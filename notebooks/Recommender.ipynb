{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# Load the MovieLens 100k dataset. Only five\n",
    "# star ratings are treated as positive.\n",
    "data = fetch_movielens(min_rating=5.0)\n",
    "\n",
    "train = data['train']\n",
    "test = data['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model = LightFM(learning_rate=0.05, loss='bpr')\n",
    "model.fit(train, epochs=10)\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.35, test 0.06.\n",
      "AUC: train 0.97, test 0.93.\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "# loss functions: logistic, BPR, WARP, k-OS WARP\n",
    "# can pass in item and user features\n",
    "\n",
    "# fit_partial for incremental training\n",
    "model.fit_partial(train, epochs=30, num_threads=2)\n",
    "# item_features, user_features\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known positives: {'Glory (1989)', 'Butch Cassidy and the Sundance Kid (1969)', 'Empire Strikes Back, The (1980)', 'Terminator, The (1984)', 'Lawrence of Arabia (1962)', 'Aliens (1986)', 'Full Metal Jacket (1987)', 'Jurassic Park (1993)', 'Die Hard (1988)', 'Contact (1997)', 'Professional, The (1994)', 'Pulp Fiction (1994)', 'Star Trek: The Wrath of Khan (1982)', 'Raiders of the Lost Ark (1981)', 'Star Trek: First Contact (1996)', 'Star Trek III: The Search for Spock (1984)', 'Godfather, The (1972)', 'Alien (1979)'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Star Wars (1977)',\n",
       " 'Return of the Jedi (1983)',\n",
       " 'Braveheart (1995)',\n",
       " 'Fugitive, The (1993)',\n",
       " 'Shawshank Redemption, The (1994)',\n",
       " 'Princess Bride, The (1987)',\n",
       " 'Silence of the Lambs, The (1991)',\n",
       " 'Terminator 2: Judgment Day (1991)',\n",
       " 'Indiana Jones and the Last Crusade (1989)',\n",
       " 'Forrest Gump (1994)']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# source: https://github.com/amkurian/movie-recommendation-system/blob/master/recommender.py\n",
    "def recommend(user_id):\n",
    "    n_users, n_items = data['train'].shape\n",
    "    known_positives = set(data['item_labels'][data['train'].tocsr()[user_id].indices])\n",
    "\n",
    "    want_predictions_for = np.arange(n_items)\n",
    "    scores = model.predict(user_id, want_predictions_for)\n",
    "    \n",
    "    top_items = [x for x in data['item_labels'][np.argsort(-scores)] if x not in known_positives]\n",
    "    print('known positives:', known_positives)\n",
    "    return top_items[:10]\n",
    "    \n",
    "recommend(7)\n",
    "\n",
    "'''\n",
    ".predict_rank()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightfm\n",
    "https://towardsdatascience.com/how-to-build-a-movie-recommender-system-in-python-using-lightfm-8fa49d7cbe3b\n",
    "https://towardsdatascience.com/solving-business-usecases-by-recommender-system-using-lightfm-4ba7b3ac8e62\n",
    "\n",
    "### tensorrec\n",
    "https://hackernoon.com/tensorrec-a-recommendation-engine-framework-in-tensorflow-d85e4f0874e8\n",
    "https://gist.github.com/kayibal/16340660d1d85b9ea1872a5d9be0f383\n",
    "\n",
    "### surprise\n",
    "https://medium.com/hacktive-devs/recommender-system-made-easy-with-scikit-surprise-569cbb689824\n",
    "https://realpython.com/build-recommendation-engine-collaborative-filtering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "ratings_dict = {\n",
    "    \"item\": [1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
    "    \"user\": ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D', 'E'],\n",
    "    \"rating\": [1, 2, 2, 4, 2.5, 4, 4.5, 5, 3],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Loads Pandas dataframe\n",
    "data = Dataset.load_from_df(df[[\"user\", \"item\", \"rating\"]], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed).\n",
    "# data = Dataset.load_builtin('ml-1m')\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.1309  2.1219  1.6636  0.2364  0.7927  1.3891  0.7546  \n",
      "MAE (testset)     2.0714  2.1071  1.6357  0.2355  0.7927  1.3685  0.7384  \n",
      "Fit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([2.13091913, 2.12192154, 1.66364688, 0.23643617, 0.79272128]),\n",
       " 'test_mae': array([2.07142857, 2.10714286, 1.63573323, 0.23548396, 0.79272128]),\n",
       " 'fit_time': (0.0013074874877929688,\n",
       "  0.0016717910766601562,\n",
       "  0.0011878013610839844,\n",
       "  0.0011448860168457031,\n",
       "  0.0012860298156738281),\n",
       " 'test_time': (4.935264587402344e-05,\n",
       "  3.814697265625e-05,\n",
       "  4.3392181396484375e-05,\n",
       "  4.1484832763671875e-05,\n",
       "  3.314018249511719e-05)}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD, NMF, CoClustering, KNNBasic, KNNWithMeans\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "algo = NMF()\n",
    "\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = data.build_full_trainset()\n",
    "model = algo.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='E', iid=2, r_ui=None, est=3.068125689180161, details={'was_impossible': False})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('E', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
